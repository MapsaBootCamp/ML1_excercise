{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder-Decoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpI2kb8Qn5tp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import BatchNormalization, Conv2D, Dense, Flatten, Lambda, LeakyReLU\n",
        "from keras.layers import Conv2DTranspose, Reshape\n",
        "import keras.backend as k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "OhY_3CRQyw98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b1182a-e4ad-4da9-b432-6241b383365c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = np.reshape(x_train, newshape=(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)) \n",
        "x_test = np.reshape(x_test, newshape=(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1))"
      ],
      "metadata": {
        "id": "6zilIoBmutvO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "def build_encoder(image_shape = (28, 28, 1), latent_dim = 2):\n",
        "\n",
        "  def sampeling(mu_logvar):\n",
        "    mu, logvar = mu_logvar\n",
        "    epsilon = k.random_normal(shape=k.shape(mu), mean=0, stddev=1)\n",
        "    return mu + k.exp(1/2 * logvar) * epsilon\n",
        "\n",
        "  input = tf.keras.Input(shape=image_shape)\n",
        "\n",
        "  conv2d = Conv2D(1, kernel_size=(3, 3), strides=(1, 1), padding='same')(input)\n",
        "  batch_norm = BatchNormalization()(conv2d)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  conv2d = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(leaky)\n",
        "  batch_norm = BatchNormalization()(conv2d)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  conv2d = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same')(leaky)\n",
        "  batch_norm = BatchNormalization()(conv2d)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  conv2d = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same')(leaky)\n",
        "  batch_norm = BatchNormalization()(conv2d)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  conv2d = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(leaky)\n",
        "  batch_norm = BatchNormalization()(conv2d)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  flatten = Flatten()(leaky)\n",
        "  mu = Dense(latent_dim)(flatten)\n",
        "  logvar = Dense(latent_dim)(flatten)\n",
        "  output = Lambda(sampeling)((mu, logvar))\n",
        "\n",
        "  model = tf.keras.Model(inputs=input, outputs=output, name=\"encoder_model\")\n",
        "  model.summary()\n",
        "  return model, mu, logvar\n"
      ],
      "metadata": {
        "id": "0h4_t3UrvH4w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_encoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXjLYMNA1bBI",
        "outputId": "83845391-0e12-4d85-80a6-e78a3f6ab4ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 28, 28, 1)    10          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 28, 28, 1)   4           ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 28, 28, 1)    0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 28, 28, 32)   320         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 28, 28, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 14, 14, 64)   18496       ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 14, 14, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 7, 7, 64)     36928       ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 7, 7, 64)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 7, 7, 64)     36928       ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 7, 7, 64)     0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 3136)         0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            6274        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            6274        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 2)            0           ['dense[0][0]',                  \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,130\n",
            "Trainable params: 105,680\n",
            "Non-trainable params: 450\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<keras.engine.functional.Functional at 0x7f1b9049a2d0>,\n",
              " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'dense')>,\n",
              " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'dense_1')>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_decoder(latent_dim = 2):\n",
        "  input = tf.keras.Input(shape=latent_dim)\n",
        "  dense = Dense(3136)(input)\n",
        "  reshaped_input = Reshape(target_shape=(7, 7, 64))(dense)\n",
        "\n",
        "  conv_trans = Conv2DTranspose(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(reshaped_input)\n",
        "  batch_norm = BatchNormalization()(conv_trans)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  conv_trans = Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same')(leaky)\n",
        "  batch_norm = BatchNormalization()(conv_trans)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)\n",
        "\n",
        "  conv_trans = Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same')(leaky)\n",
        "  batch_norm = BatchNormalization()(conv_trans)\n",
        "  leaky = LeakyReLU(0.2)(batch_norm)  \n",
        "\n",
        "  conv_trans = Conv2DTranspose(1, kernel_size=(3, 3), strides=(1, 1), padding='same')(leaky)\n",
        "  output = LeakyReLU(0.2)(conv_trans)\n",
        "\n",
        "  model = tf.keras.Model(inputs=input, outputs=output, name=\"decoder_model\")\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "YpoWFmCA402H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_decoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd1G-j5cSclM",
        "outputId": "214abedb-ed73-42d7-dc8f-c8afd65820d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 64)         36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 7, 7, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 28, 28, 1)        577       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,537\n",
            "Trainable params: 121,153\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f1b903f0d10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(encoder_mu, encoder_logvar):\n",
        "    def vae_reconstruction_loss(y_true, y_predict):\n",
        "        reconstruction_loss_factor = 1000\n",
        "        reconstruction_loss = k.mean(k.square(y_true-y_predict), axis=[1, 2, 3])\n",
        "        return reconstruction_loss_factor * reconstruction_loss\n",
        "\n",
        "    def vae_kl_loss(encoder_mu, encoder_logvar):\n",
        "        kl_loss = -0.5 * k.sum(1.0 + encoder_logvar - k.square(encoder_mu) - k.exp(encoder_logvar), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_kl_loss_metric(y_true, y_predict):\n",
        "        kl_loss = -0.5 * k.sum(1.0 + encoder_logvar - k.square(encoder_mu) - k.exp(encoder_logvar), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_loss(y_true, y_predict):\n",
        "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
        "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
        "\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    return vae_loss"
      ],
      "metadata": {
        "id": "kU_wmzOmUSKU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae(encoder, decoder, image_shape = (28, 28, 1)):\n",
        "\n",
        "  input = tf.keras.Input(shape= image_shape, name=\"VAE_input\")\n",
        "  _, mu, logvar = build_encoder()\n",
        "\n",
        "  encoder_output = encoder(input)\n",
        "  decoder_output = decoder(encoder_output)\n",
        "\n",
        "  vae = tf.keras.models.Model(inputs= input, outputs= decoder_output, name=\"VAE_model\")\n",
        "  vae.summary()\n",
        "\n",
        "  vae.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0005), loss=loss_func(mu, logvar))\n",
        "  return vae\n"
      ],
      "metadata": {
        "id": "m7N3sHvTSfdY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder, _, _ = build_encoder()\n",
        "decoder = build_decoder()\n",
        "vae_model = vae(encoder, decoder)\n",
        "\n",
        "vae_model.fit(x_train, x_train, epochs=20, batch_size=32, shuffle=True, validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT7JJSSrTuOI",
        "outputId": "c0ba8272-21de-44d7-c57f-d22491582fad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 28, 28, 1)    10          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 28, 28, 1)   4           ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 28, 28, 1)    0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 28, 28, 32)   320         ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 28, 28, 32)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 14, 14, 64)   18496       ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 14, 14, 64)  256         ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 14, 14, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 7, 7, 64)     36928       ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 7, 7, 64)    256         ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 7, 7, 64)     0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 7, 7, 64)     36928       ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 7, 7, 64)    256         ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 7, 7, 64)     0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 3136)         0           ['leaky_re_lu_13[0][0]']         \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 2)            6274        ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 2)            6274        ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 2)            0           ['dense_3[0][0]',                \n",
            "                                                                  'dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,130\n",
            "Trainable params: 105,680\n",
            "Non-trainable params: 450\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 7, 7, 64)         36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 7, 7, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 14, 14, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 14, 14, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 28, 28, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 28, 28, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_16 (LeakyReLU)  (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 1)        577       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,537\n",
            "Trainable params: 121,153\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Model: \"encoder_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 28, 28, 1)    10          ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 28, 28, 1)   4           ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 28, 28, 1)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 28, 28, 32)   320         ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 28, 28, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 28, 28, 32)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 14, 14, 64)   18496       ['leaky_re_lu_19[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 14, 14, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 14, 14, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 7, 7, 64)     36928       ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 7, 7, 64)    256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 7, 7, 64)     0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 7, 7, 64)     36928       ['leaky_re_lu_21[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 7, 7, 64)    256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 7, 7, 64)     0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 3136)         0           ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 2)            6274        ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 2)            6274        ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 2)            0           ['dense_6[0][0]',                \n",
            "                                                                  'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,130\n",
            "Trainable params: 105,680\n",
            "Non-trainable params: 450\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"VAE_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " VAE_input (InputLayer)      [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder_model (Functional)  (None, 2)                 106130    \n",
            "                                                                 \n",
            " decoder_model (Functional)  (None, 28, 28, 1)         121537    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227,667\n",
            "Trainable params: 226,833\n",
            "Non-trainable params: 834\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 45s 17ms/step - loss: 56.5552 - val_loss: 50.9347\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 49.2749 - val_loss: 47.6298\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 47.1011 - val_loss: 45.9603\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 45.6854 - val_loss: 44.7991\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 44.7539 - val_loss: 45.0649\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 44.0634 - val_loss: 44.9821\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 43.5081 - val_loss: 43.2907\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 43.1185 - val_loss: 43.7107\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 42.7091 - val_loss: 42.5933\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 42.4339 - val_loss: 41.9800\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 42.1273 - val_loss: 42.1213\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 41.9187 - val_loss: 41.7741\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 41.7011 - val_loss: 42.0293\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 41.5118 - val_loss: 41.9115\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 41.2998 - val_loss: 41.3507\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 41.1433 - val_loss: 41.4159\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 40.9764 - val_loss: 41.9797\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 40.8686 - val_loss: 41.0033\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 40.7085 - val_loss: 41.1307\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 40.6102 - val_loss: 41.6068\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b9022ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "encoded_data = encoder.predict(x_test)\n",
        "decoded_data = decoder.predict(encoded_data)"
      ],
      "metadata": {
        "id": "xC0ySAIRZExT"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}