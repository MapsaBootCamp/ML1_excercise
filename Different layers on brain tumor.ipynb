{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fda4acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.8/site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ec198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c4ceab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_yes = [cv2.imread(file) for file in glob.glob(\"data/yes/*.*\")]\n",
    "images_no = [cv2.imread(file) for file in glob.glob(\"data/no/*.*\")]\n",
    "len(images_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8e58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_crop(image_path):\n",
    "    cropped_image = []\n",
    "    for i in image_path:\n",
    "        if i is None:\n",
    "            pass\n",
    "        else:\n",
    "            image = cv2.resize(i , (128,128))\n",
    "        \n",
    "        #The initial processing of the image\n",
    "        image = cv2.medianBlur(image, 3)\n",
    "        image_bw = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #The declaration of CLAHE \n",
    "        #clipLimit -> Threshold for contrast limiting\n",
    "        clahe = cv2.createCLAHE(clipLimit = 5)\n",
    "        final_img = clahe.apply(image_bw)\n",
    "        cropped_image.append(final_img)\n",
    "    cropped_image = np.array(cropped_image)\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3387fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images_no = image_crop(images_no)\n",
    "cropped_images_yes = image_crop(images_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3db3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_yes = np.ones(len(cropped_images_yes), dtype=\"int8\")\n",
    "y_no = np.zeros(len(cropped_images_no), dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20edfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((cropped_images_yes, cropped_images_no), axis=0)\n",
    "y = np.concatenate((y_yes, y_no), axis=0)\n",
    "\n",
    "d1, d2, d3 = X.shape\n",
    "X_1 = X.reshape((d1, d2 * d3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae38a5",
   "metadata": {},
   "source": [
    "## Functional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba4b8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_1, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ca0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 16384)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c170c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13739906",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(128*128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d64d4093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 16384])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea3f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c21fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf0fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"functional_tumor_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8db4360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_tumor_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16384)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1048640   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,053,450\n",
      "Trainable params: 1,053,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67f74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "X_train = X_train_f / 255\n",
    "X_test = X_test_f / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff35ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e2cad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 137ms/step - loss: 11.5951 - accuracy: 0.2733 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 12.0211 - accuracy: 0.3540 - val_loss: 11.0444 - val_accuracy: 0.4146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_f, y_train_f, batch_size=64, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44f637cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 10.1425 - accuracy: 0.4706 - 51ms/epoch - 25ms/step\n",
      "Test loss: 10.142546653747559\n",
      "Test accuracy: 0.47058823704719543\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(X_test_f, y_test_f, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a09636",
   "metadata": {},
   "source": [
    "## Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad731e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \n",
    "#     Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "#     Converts z, the encoded digit vector, back into a readable digit.\n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_output = layers.Dense(original_dim, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(keras.Model):\n",
    "#     Combines the encoder and decoder into an end-to-end model for training.\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_dim,\n",
    "        intermediate_dim=64,\n",
    "        latent_dim=32,\n",
    "        name=\"autoencoder\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "        )\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "321ac50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a33e36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = nan\n",
      "step 100: mean loss = nan\n",
      "step 200: mean loss = nan\n",
      "Start of epoch 1\n",
      "step 0: mean loss = nan\n",
      "step 100: mean loss = nan\n",
      "step 200: mean loss = nan\n"
     ]
    }
   ],
   "source": [
    "original_dim = 128\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train_s)\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(epochs):\n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed = vae(x_batch_train)\n",
    "            # Compute reconstruction loss\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(vae.losses)  # Add KLD regularization loss\n",
    "\n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2304f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WHY LOSS IS NAN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9706a0",
   "metadata": {},
   "source": [
    "#### OR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7a10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 1s 15ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 23ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 18ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd8076d130>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_model = VariationalAutoEncoder(128, 64, 32)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "vae_model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "vae_model.fit(X_train_f, y_train_f, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d425db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = vae_model.evaluate(X_test_f, y_test_f, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
